{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from os.path import dirname, join as pjoin\n",
    "import scipy.io as sio\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "\n",
    "from func2graph import data, baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sessions are preprocessed by sliding windows, num_unqiue_cell_types and num_unique_neurons are known\n",
    "# session1 = torch.rand(32, 10, 100)\n",
    "# session2 = torch.rand(30, 13, 100)\n",
    "# session1_cell_type_ids = torch.rand(32, 10)\n",
    "# session2_cell_type_ids = torch.rand(30, 13)\n",
    "# session1_neuron_ids = torch.rand(32, 10)\n",
    "# session2_neuron_ids = torch.rand(30, 13)\n",
    "\n",
    "# all_sessions = [session1, session2]\n",
    "# all_sessions_cell_type_ids = [session1_cell_type_ids, session2_cell_type_ids]\n",
    "# all_sessions_neuron_ids = [session1_neuron_ids, session2_neuron_ids]\n",
    "\n",
    "\n",
    "# # all_sessions_activity_windows\n",
    "# # all_sessions_new_UniqueID_windows\n",
    "# # all_sessions_new_cell_type_id_windows\n",
    "# class Mouse_Session_Dataset(TensorDataset):\n",
    "#     def __init__(\n",
    "#         self, \n",
    "#         all_sessions_activity_windows,  # list of 3d tensors, each tensor is a session (num_window x n x window_size)) \n",
    "#         all_sessions_new_UniqueID_windows,  # list of 2d tensors, each tensor is a session (num_window x n)\n",
    "#         all_sessions_new_cell_type_id_windows, # list of 2d tensors, each tensor is a session (num_window x n)\n",
    "#         batch_size=3,                      # real batch size !!!!!!!!!!!!!!!!!\n",
    "#     ):\n",
    "#         num_batch_per_session = [session.shape[0] // batch_size for session in all_sessions_activity_windows]\n",
    "\n",
    "#         self.all_batch = []\n",
    "#         self.all_batch_neuron_ids = []\n",
    "#         self.all_batch_cell_type_ids = []\n",
    "#         for i in range(len(num_batch_per_session)):      # for each session\n",
    "#             for j in range(num_batch_per_session[i]):      # for each batch\n",
    "#                 self.all_batch.append(all_sessions_activity_windows[i][j*batch_size:(j+1)*batch_size])\n",
    "#                 self.all_batch_neuron_ids.append(all_sessions_new_UniqueID_windows[i][j*batch_size:(j+1)*batch_size])\n",
    "#                 self.all_batch_cell_type_ids.append(all_sessions_new_cell_type_id_windows[i][j*batch_size:(j+1)*batch_size])\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         return self.all_batch[index], self.all_batch_neuron_ids[index], self.all_batch_cell_type_ids[index]\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.all_batch)\n",
    "\n",
    "\n",
    "\n",
    "# dataset = Mouse_Session_Dataset(all_sessions, all_sessions_cell_type_ids, all_sessions_neuron_ids, batch_size=32)\n",
    "# dataloader = DataLoader(dataset, batch_size=1, shuffle=False)    # this is not real batch_size\n",
    "\n",
    "# for idx, (batch, batch_neuron_ids, batch_cell_type_ids) in enumerate(dataloader):\n",
    "#     batch = batch.squeeze(0)                 # remove the fake batch_size\n",
    "#     batch_cell_type_ids = batch_cell_type_ids.squeeze(0)\n",
    "#     batch_neuron_ids = batch_neuron_ids.squeeze(0)\n",
    "#     print(idx, batch.shape, batch_cell_type_ids.shape, batch_neuron_ids.shape)\n",
    "\n",
    "#     if idx == 11:\n",
    "#         print(batch_cell_type_ids[1])\n",
    "#         print(batch_neuron_ids[1])\n",
    "#         print(session2_cell_type_ids[4])\n",
    "#         print(session2_neuron_ids[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  6.   8.   9.  10.  11.  12.  13.  14.  15.  16.  17.  18.  19.  20.\n",
      "  21.  23.  25.  28.  29.  30.  31.  32.  33.  34.  35.  37.  39.  40.\n",
      "  41.  41.  42.  43.  45.  45.  46.  47.  47.  48.  48.  49.  50.  51.\n",
      "  52.  53.  53.  54.  55.  56.  58.  59.  60.  61.  63.  65.  65.  66.\n",
      "  67.  68.  72.  73.  74.  75.  76.  77.  79.  80.  81.  82.  83.  84.\n",
      "  85.  85.  86.  87.  88.  89.  91.  91.  92.  93.  94.  96.  96.  97.\n",
      "  98.  98.  99. 100. 101. 102. 103. 103. 105. 106. 107. 108. 108. 109.\n",
      " 110. 111. 113. 114. 115. 116. 117. 117. 118. 119. 120. 121. 122. 124.\n",
      " 125. 126. 127. 127. 128. 130. 131. 131. 132. 133. 134. 134. 136. 137.\n",
      " 138. 139. 140. 141. 142. 144. 145. 146. 147. 148. 149. 149. 150. 151.\n",
      " 152. 152. 154. 154. 155. 157. 158. 158. 161. 163. 164. 165. 166. 166.\n",
      " 167. 169. 170. 171. 172. 173. 173. 174. 175. 176. 177. 177. 180. 181.\n",
      " 181. 182. 184. 184. 185. 187. 189. 190. 191. 192. 193. 194. 197. 197.\n",
      " 200. 204. 205. 206. 210. 211. 212. 213. 214. 215. 215. 217. 220. 221.\n",
      " 222. 223. 225. 226. 227. 228. 231. 232. 233. 234. 236. 240. 242. 243.\n",
      " 244. 246. 248. 249. 252. 252. 253. 254. 256. 257. 258. 259. 260. 262.\n",
      " 263. 266. 267. 268. 269. 270. 271. 273. 274. 275. 282. 283. 287. 288.\n",
      " 289. 290. 296. 299. 300. 302. 303. 304. 304. 305. 305. 306. 306. 307.\n",
      " 308. 309. 310. 311. 312. 312. 313. 314. 314. 315. 316. 318. 318. 320.\n",
      " 321. 321. 322. 324. 325. 326. 327. 329. 330. 331. 332. 335. 337. 337.\n",
      " 338. 338. 341. 342. 343. 344. 345. 347. 348. 350. 351. 352. 353. 355.\n",
      " 356. 357. 358. 359. 360. 362. 363. 365. 367. 368. 369. 371. 372. 376.\n",
      " 377. 378. 379. 380. 382. 383. 383. 385. 386. 386. 387. 388. 388. 389.\n",
      " 390. 390. 391. 392. 393. 394. 395. 396. 398. 399. 400. 402. 404. 405.\n",
      " 406. 407. 408. 409. 410. 411. 412. 418. 421. 422. 423. 424. 428. 429.\n",
      " 430. 432. 434.]\n",
      "[460, 178, 522, 497]\n"
     ]
    }
   ],
   "source": [
    "directory = '../../data/Mouse/Bugeon/'\n",
    "input_sessions_file_path = [\n",
    "    {'date_exp': 'SB025/2019-10-07/', 'input_setting': 'Blank/01/'},\n",
    "    {'date_exp': 'SB025/2019-10-04/', 'input_setting': 'Blank/01/'},\n",
    "    {'date_exp': 'SB025/2019-10-08/', 'input_setting': 'Blank/01/'},\n",
    "    {'date_exp': 'SB025/2019-10-09/', 'input_setting': 'Blank/01/'},\n",
    "]\n",
    "normalization = 'session'  ##############################!!!!!!!!!!!!!\n",
    "\n",
    "all_sessions_original_UniqueID = []\n",
    "all_sessions_original_cell_type = []\n",
    "all_sessions_acitvity_TRAIN = []   # first 80% of the time\n",
    "all_sessions_acitvity_VAL = []\n",
    "num_neurons_per_session = []\n",
    "\n",
    "for i in range(len(input_sessions_file_path)):\n",
    "    date_exp = input_sessions_file_path[i]['date_exp']\n",
    "    input_setting = input_sessions_file_path[i]['input_setting']\n",
    "\n",
    "    activity, frame_times, UniqueID, neuron_ttypes = data.load_mouse_data_session(\n",
    "        directory, date_exp, input_setting, normalization\n",
    "    )\n",
    "\n",
    "    all_sessions_original_UniqueID.append(UniqueID)\n",
    "    all_sessions_original_cell_type.append(neuron_ttypes)\n",
    "    all_sessions_acitvity_TRAIN.append(activity[:, :int(activity.shape[1]*0.8)])\n",
    "    all_sessions_acitvity_VAL.append(activity[:, int(activity.shape[1]*0.8):])\n",
    "    num_neurons_per_session.append(activity.shape[0])\n",
    "\n",
    "\n",
    "all_sessions_original_UniqueID = np.concatenate(all_sessions_original_UniqueID)\n",
    "all_sessions_original_cell_type = np.concatenate(all_sessions_original_cell_type)\n",
    "print(np.sort(all_sessions_original_UniqueID[~np.isnan(all_sessions_original_UniqueID)]))\n",
    "# get the index of accumulated UniqueID = 111\n",
    "# print(accumulate_cell_type[np.where(accumulate_UnqiueID == 304)])\n",
    "# print(accumulate_UnqiueID[np.where(accumulate_cell_type == 'Vip-Ptprt-Pkp2')])\n",
    "\n",
    "print(num_neurons_per_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EC', 'IN', 'IN', 'Lamp5', 'EC', 'IN', 'EC', 'EC', 'IN', 'EC', 'EC', 'EC', 'IN', 'Pvalb', 'EC', 'EC', 'EC', 'Lamp5', 'EC', 'EC', 'EC', 'IN', 'EC', 'EC', 'IN', 'EC', 'IN', 'EC', 'EC', 'IN', 'EC', 'EC', 'EC', 'EC', 'EC', 'EC', 'EC', 'EC', 'EC', 'EC', 'EC', 'IN', 'EC', 'EC', 'EC', 'EC', 'IN', 'IN', 'EC', 'IN', 'EC', 'IN', 'IN', 'EC', 'IN', 'Lamp5', 'EC', 'IN', 'IN', 'Lamp5', 'IN', 'Lamp5', 'EC', 'EC', 'Vip', 'IN', 'IN', 'EC', 'Lamp5', 'EC', 'Lamp5', 'Lamp5', 'IN', 'IN', 'EC', 'IN', 'Lamp5', 'IN', 'Lamp5', 'IN', 'EC', 'EC', 'Lamp5', 'Lamp5', 'EC', 'IN', 'EC', 'EC', 'EC', 'EC', 'EC', 'EC', 'EC', 'EC', 'IN', 'EC', 'EC', 'EC', 'EC', 'Lamp5']\n",
      "------------------------------------\n",
      "1657\n",
      "1657\n",
      "[253.]\n",
      "[188.]\n",
      "------------------------------------\n",
      "['EC' 'IN' 'IN' 'Lamp5-Lsp1' 'EC' 'IN' 'EC' 'EC' 'IN' 'EC' 'EC' 'EC' 'IN'\n",
      " 'Pvalb-Tpbg' 'EC' 'EC' 'EC' 'Lamp5-Fam19a1-Pax6' 'EC' 'EC' 'EC' 'IN' 'EC'\n",
      " 'EC' 'IN' 'EC' 'IN' 'EC' 'EC' 'IN' 'EC' 'EC' 'EC' 'EC' 'EC' 'EC' 'EC'\n",
      " 'EC' 'EC' 'EC' 'EC' 'IN' 'EC' 'EC' 'EC' 'EC' 'IN' 'IN' 'EC' 'IN' 'EC'\n",
      " 'IN' 'IN' 'EC' 'IN' 'Lamp5-Fam19a1-Pax6' 'EC' 'IN' 'IN'\n",
      " 'Lamp5-Fam19a1-Tmem182' 'IN' 'Lamp5-Lsp1' 'EC' 'EC' 'Vip-Igfbp4-Mab21l1'\n",
      " 'IN' 'IN' 'EC' 'Lamp5-Plch2-Dock5' 'EC' 'Lamp5-Plch2-Dock5'\n",
      " 'Lamp5-Fam19a1-Tmem182' 'IN' 'IN' 'EC' 'IN' 'Lamp5-Plch2-Dock5' 'IN'\n",
      " 'Lamp5-Lsp1' 'IN' 'EC' 'EC' 'Lamp5-Krt73' 'Lamp5-Fam19a1-Tmem182' 'EC'\n",
      " 'IN' 'EC' 'EC' 'EC' 'EC' 'EC' 'EC' 'EC' 'EC' 'IN' 'EC' 'EC' 'EC' 'EC'\n",
      " 'Lamp5-Fam19a1-Pax6']\n",
      "[6. 0. 0. 7. 6. 0. 6. 6. 0. 6. 6. 6. 0. 1. 6. 6. 6. 7. 6. 6. 6. 0. 6. 6.\n",
      " 0. 6. 0. 6. 6. 0. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 0. 6. 6. 6. 6. 0. 0.\n",
      " 6. 0. 6. 0. 0. 6. 0. 7. 6. 0. 0. 7. 0. 7. 6. 6. 5. 0. 0. 6. 7. 6. 7. 7.\n",
      " 0. 0. 6. 0. 7. 0. 7. 0. 6. 6. 7. 7. 6. 0. 6. 6. 6. 6. 6. 6. 6. 6. 0. 6.\n",
      " 6. 6. 6. 7.]\n",
      "{'IN': 0, 'Pvalb': 1, 'Serpinf1': 2, 'Sncg': 3, 'Sst': 4, 'Vip': 5, 'EC': 6, 'Lamp5': 7}\n",
      "['Lamp5-Lsp1' 'Lamp5-Lsp1' 'Lamp5-Lsp1' 'Lamp5-Lsp1' 'Lamp5-Lsp1'\n",
      " 'Lamp5-Lsp1' 'Lamp5-Lsp1' 'Lamp5-Lsp1' 'Lamp5-Lsp1' 'Lamp5-Lsp1']\n",
      "[7. 7. 7. 7. 7. 7. 7. 7. 7. 7.]\n",
      "------------------------------------\n",
      "1616\n"
     ]
    }
   ],
   "source": [
    "all_sessions_new_UniqueID, num_unqiue_neurons = assign_unique_neuron_ids(all_sessions_original_UniqueID, num_neurons_per_session)\n",
    "all_sessions_new_cell_type_id, cell_type2id = assign_unique_cell_type_ids(all_sessions_original_cell_type, num_neurons_per_session)\n",
    "\n",
    "\n",
    "# PLEASE come up with tests to test the correctness of the above functions!!!!!!!!!!!!!!!!\n",
    "\n",
    "# test assign_unique_neuron_ids()\n",
    "new_UniqueID = np.concatenate(all_sessions_new_UniqueID)\n",
    "old_UniqueID = all_sessions_original_UniqueID\n",
    "print('------------------------------------')\n",
    "print(len(old_UniqueID))\n",
    "print(len(new_UniqueID))\n",
    "print(old_UniqueID[np.where(old_UniqueID == 253)])\n",
    "print(new_UniqueID[np.where(old_UniqueID == 253)])\n",
    "\n",
    "# test assign_unique_cell_type_ids()\n",
    "cell_type_id = np.concatenate(all_sessions_new_cell_type_id)\n",
    "cell_type = all_sessions_original_cell_type\n",
    "\n",
    "print('------------------------------------')\n",
    "print(cell_type[:100])\n",
    "print(cell_type_id[:100])\n",
    "print(cell_type2id)\n",
    "print(cell_type[np.where(cell_type == 'Lamp5-Lsp1')])\n",
    "print(cell_type_id[np.where(cell_type == 'Lamp5-Lsp1')])\n",
    "\n",
    "print('------------------------------------')\n",
    "print(num_unqiue_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_windows of session 0:  4180\n",
      "num_batch of session 0:  130\n",
      "num_windows of session 1:  4178\n",
      "num_batch of session 1  130\n",
      "num_windows of session 2:  4179\n",
      "num_batch of session 2  130\n",
      "num_windows of session 3:  4177\n",
      "num_batch of session 3  130\n",
      "len of train_dataloader:  520\n",
      "below should be the same -------------------\n",
      "tensor([[ 0.4185, -0.1525, -0.2576,  ..., -0.2576, -0.2576, -0.2576],\n",
      "        [-0.2576, -0.2576, -0.2576,  ..., -0.2576, -0.2576, -0.2576],\n",
      "        [-0.2576, -0.2576, -0.2576,  ..., -0.2576, -0.2576, -0.2576],\n",
      "        ...,\n",
      "        [-0.2576, -0.2576, -0.2576,  ..., -0.2576,  0.5900, -0.2576],\n",
      "        [ 0.0508, -0.2576, -0.2576,  ..., -0.2576, -0.2576, -0.2576],\n",
      "        [-0.2576,  0.7985, -0.2576,  ...,  0.5101, -0.2576, -0.2576]],\n",
      "       dtype=torch.float64)\n",
      "[[ 0.41853568 -0.15247084 -0.25757274 ... -0.25757274 -0.25757274\n",
      "  -0.25757274]\n",
      " [-0.25757274 -0.25757274 -0.25757274 ... -0.25757274 -0.25757274\n",
      "  -0.25757274]\n",
      " [-0.25757274 -0.25757274 -0.25757274 ... -0.25757274 -0.25757274\n",
      "  -0.25757274]\n",
      " ...\n",
      " [-0.25757274 -0.25757274 -0.25757274 ... -0.25757274  0.58996767\n",
      "  -0.25757274]\n",
      " [ 0.05082612 -0.25757274 -0.25757274 ... -0.25757274 -0.25757274\n",
      "  -0.25757274]\n",
      " [-0.25757274  0.79850686 -0.25757274 ...  0.51008087 -0.25757274\n",
      "  -0.25757274]]\n"
     ]
    }
   ],
   "source": [
    "# For TRAIN\n",
    "all_sessions_activity_windows_TRAIN, all_sessions_new_UniqueID_windows_TRAIN, all_sessions_new_cell_type_id_window_TRAIN = sliding_windows(\n",
    "    all_sessions_acitvity_TRAIN, all_sessions_new_UniqueID, all_sessions_new_cell_type_id, window_size=20\n",
    ")\n",
    "\n",
    "# For VAL\n",
    "all_sessions_activity_windows_VAL, all_sessions_new_UniqueID_windows_VAL, all_sessions_new_cell_type_id_window_VAL = sliding_windows(\n",
    "    all_sessions_acitvity_VAL, all_sessions_new_UniqueID, all_sessions_new_cell_type_id, window_size=20\n",
    ")\n",
    "\n",
    "train_dataset = Mouse_All_Sessions_Dataset(\n",
    "    all_sessions_activity_windows_TRAIN, \n",
    "    all_sessions_new_UniqueID_windows_TRAIN, \n",
    "    all_sessions_new_cell_type_id_window_TRAIN, \n",
    "    batch_size=32,        ###### real batch_size!!!!!!!!!!!!!!!!!!!!\n",
    ") \n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=False)    # this is not real batch_size\n",
    "\n",
    "print('num_windows of session 0: ', len(all_sessions_activity_windows_TRAIN[0]))\n",
    "print('num_batch of session 0: ', len(all_sessions_activity_windows_TRAIN[0]) // 32)\n",
    "print('num_windows of session 1: ', len(all_sessions_activity_windows_TRAIN[1]))\n",
    "print('num_batch of session 1 ', len(all_sessions_activity_windows_TRAIN[1]) // 32)\n",
    "print('num_windows of session 2: ', len(all_sessions_activity_windows_TRAIN[2]))\n",
    "print('num_batch of session 2 ', len(all_sessions_activity_windows_TRAIN[2]) // 32)\n",
    "print('num_windows of session 3: ', len(all_sessions_activity_windows_TRAIN[3]))\n",
    "print('num_batch of session 3 ', len(all_sessions_activity_windows_TRAIN[3]) // 32)\n",
    "\n",
    "print('len of train_dataloader: ', len(train_dataloader))\n",
    "\n",
    "# batch idx for the second batch os session 1\n",
    "batch_idx = len(all_sessions_activity_windows_TRAIN[0]) // 32 + 1\n",
    "\n",
    "# test correctness\n",
    "for idx, (batch, batch_neuron_ids, batch_cell_type_ids) in enumerate(train_dataloader):\n",
    "    batch = batch.squeeze(0)                 # remove the fake batch_size\n",
    "    batch_neuron_ids = batch_neuron_ids.squeeze(0)\n",
    "    batch_cell_type_ids = batch_cell_type_ids.squeeze(0)\n",
    "    # print(idx, batch.shape, batch_neuron_ids.shape, batch_cell_type_ids.shape)\n",
    "\n",
    "    if idx == batch_idx:\n",
    "        print('below should be the same -------------------')\n",
    "        print(batch[1])\n",
    "        # print(batch_neuron_ids[1])\n",
    "        # print(batch_cell_type_ids[1])\n",
    "\n",
    "        print(all_sessions_activity_windows_TRAIN[1][32+1])  # the second window of the second batch of session 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mouse_All_Sessions_Dataset(TensorDataset):\n",
    "    def __init__(\n",
    "        self, \n",
    "        all_sessions_activity_windows,  # list of 3d tensors, each tensor is a session (num_window x n x window_size)) \n",
    "        all_sessions_new_UniqueID_windows,  # list of 2d tensors, each tensor is a session (num_window x n)\n",
    "        all_sessions_new_cell_type_id_windows, # list of 2d tensors, each tensor is a session (num_window x n)\n",
    "        batch_size=3,                      # real batch size !!!!!!!!!!!!!!!!!\n",
    "    ):\n",
    "        num_batch_per_session = [session.shape[0] // batch_size for session in all_sessions_activity_windows]\n",
    "\n",
    "        self.all_batch = []\n",
    "        self.all_batch_neuron_ids = []\n",
    "        self.all_batch_cell_type_ids = []\n",
    "        for i in range(len(num_batch_per_session)):      # for each session\n",
    "            for j in range(num_batch_per_session[i]):      # for each batch\n",
    "                self.all_batch.append(all_sessions_activity_windows[i][j*batch_size:(j+1)*batch_size])\n",
    "                self.all_batch_neuron_ids.append(all_sessions_new_UniqueID_windows[i][j*batch_size:(j+1)*batch_size])\n",
    "                self.all_batch_cell_type_ids.append(all_sessions_new_cell_type_id_windows[i][j*batch_size:(j+1)*batch_size])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.all_batch[index], self.all_batch_neuron_ids[index], self.all_batch_cell_type_ids[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_unique_neuron_ids(all_sessions_original_UniqueID, num_neurons_per_session):\n",
    "    \"\"\"\n",
    "    all_sessions_original_UniqueID: a concatenated list of the original UniqueID from all sessions\n",
    "\n",
    "    Return:\n",
    "    all_sessions_new_UniqueID: a list of sessions new UniqueID, each session is a 1D array of shape num_neurons\n",
    "    \"\"\"\n",
    "\n",
    "    # first reassign ID starting from 0 to those non-NaN neurons\n",
    "    # same IDs should be assigned to neurons that have the same original UniqueID\n",
    "    non_nan_values = all_sessions_original_UniqueID[~np.isnan(all_sessions_original_UniqueID)]\n",
    "    unique_non_nan_values = np.unique(non_nan_values)\n",
    "    id_mapping = {unique_non_nan_values[i]: i for i in range(len(unique_non_nan_values))}\n",
    "\n",
    "    new_ids = [id_mapping[non_nan_values[i]] for i in range(len(non_nan_values))]\n",
    "    all_sessions_new_UniqueID = np.copy(all_sessions_original_UniqueID)\n",
    "    all_sessions_new_UniqueID[~np.isnan(all_sessions_new_UniqueID)] = new_ids\n",
    "\n",
    "    # then assign new IDs to those NaN neurons\n",
    "    num_unique_non_nan = unique_non_nan_values.shape[0]     # new IDs start from num_unqiue_non_nan\n",
    "    num_nan = np.sum(np.isnan(all_sessions_original_UniqueID))           # new IDs end with num_non_nan + num_nan -1\n",
    "\n",
    "    new_ids = np.arange(num_unique_non_nan, num_unique_non_nan + num_nan)\n",
    "    all_sessions_new_UniqueID[np.isnan(all_sessions_new_UniqueID)] = new_ids\n",
    "\n",
    "    # Segment all_sessions_new_UniqueID into sessions\n",
    "    all_sessions_new_UniqueID = np.split(all_sessions_new_UniqueID, np.cumsum(num_neurons_per_session)[:-1])\n",
    "\n",
    "    num_unique_neurons = num_unique_non_nan + num_nan\n",
    "\n",
    "    return all_sessions_new_UniqueID, num_unique_neurons    # shape: num_sessions x num_neurons_per_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_unique_cell_type_ids(all_sessions_original_cell_type, num_neurons_per_session):\n",
    "    \"\"\"\n",
    "    all_sessions_original_cell_type: a concatenated list of the original cell types from all sessions (raw cell types)\n",
    "\n",
    "    Return:\n",
    "    all_sessions_new_cell_type: a list of sessions new cell type, each session is a 1D array of shape num_neurons\n",
    "    \"\"\"\n",
    "    # Get the first level of cell types\n",
    "    neuron_types_result = []\n",
    "    for i in range(len(all_sessions_original_cell_type)):\n",
    "        # split by \"-\"\n",
    "        neuron_types_result.append(all_sessions_original_cell_type[i].split(\"-\")[0])\n",
    "    all_sessions_original_cell_type = neuron_types_result\n",
    "    print(all_sessions_original_cell_type[:100])\n",
    "\n",
    "    unique_cell_types = list(set(all_sessions_original_cell_type))\n",
    "    # Assign IDs to cell types\n",
    "    cell_type2id = {unique_cell_types[i]: i for i in range(len(unique_cell_types))}\n",
    "\n",
    "    # Get new cell type IDs\n",
    "    all_sessions_new_cell_type_id = np.zeros(len(all_sessions_original_cell_type))\n",
    "    for i in range(len(all_sessions_original_cell_type)):\n",
    "        all_sessions_new_cell_type_id[i] = cell_type2id[all_sessions_original_cell_type[i]]\n",
    "\n",
    "    # Segment all_sessions_new_cell_type_id into sessions\n",
    "    all_sessions_new_cell_type_id = np.split(all_sessions_new_cell_type_id, np.cumsum(num_neurons_per_session)[:-1])\n",
    "\n",
    "    return all_sessions_new_cell_type_id, cell_type2id     # shape: num_sessions x num_neurons_per_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_windows(all_sessions_acitvity, all_sessions_new_UniqueID, all_sessions_new_cell_type_id, window_size):\n",
    "    \"\"\"\n",
    "    (can be from TRAIN or VAL set)\n",
    "    all_sessions_acitvity: a list of sessions activity, each session is a 2D array of shape num_neurons x num_frames\n",
    "    all_sessions_new_UniqueID: a list of sessions new UniqueID, each session is a 1D array of shape num_neurons\n",
    "    all_sessions_new_cell_type_id: a list of sessions new cell type id, each session is a 1D array of shape num_neurons\n",
    "\n",
    "    Return:\n",
    "    - all_sessions_activity_windows:\n",
    "        a list of sessions activity windows, each session is a 3D array of shape num_windows x num_neurons x window_size\n",
    "    - all_sessions_new_UniqueID_windows:\n",
    "        a list of sessions new UniqueID windows, each session is a 2D array of shape num_windows x num_neurons (each row should be the same)\n",
    "    - all_sessions_new_cell_type_id_windows:\n",
    "        a list of sessions new cell type id windows, each session is a 2D array of shape num_windows x num_neurons (each row should be the same)\n",
    "    \"\"\"\n",
    "\n",
    "    all_sessions_activity_windows = []\n",
    "    all_sessions_new_UniqueID_windows = []\n",
    "    all_sessions_new_cell_type_id_windows = []\n",
    "\n",
    "    for i in range(len(all_sessions_acitvity)):\n",
    "        num_neurons = all_sessions_acitvity[i].shape[0]\n",
    "        num_frames = all_sessions_acitvity[i].shape[1]\n",
    "        num_windows = num_frames - window_size + 1\n",
    "\n",
    "        # activity\n",
    "        activity_windows = np.zeros((num_windows, num_neurons, window_size))\n",
    "        for j in range(num_windows):\n",
    "            activity_windows[j] = all_sessions_acitvity[i][:, j:j+window_size]\n",
    "        all_sessions_activity_windows.append(activity_windows)\n",
    "\n",
    "        # UniqueID\n",
    "        UniqueID_windows = np.zeros((num_windows, num_neurons))\n",
    "        for j in range(num_windows):\n",
    "            UniqueID_windows[j] = all_sessions_new_UniqueID[i]\n",
    "        all_sessions_new_UniqueID_windows.append(UniqueID_windows)\n",
    "\n",
    "        # cell type id\n",
    "        cell_type_id_windows = np.zeros((num_windows, num_neurons))\n",
    "        for j in range(num_windows):\n",
    "            cell_type_id_windows[j] = all_sessions_new_cell_type_id[i]\n",
    "        all_sessions_new_cell_type_id_windows.append(cell_type_id_windows)\n",
    "\n",
    "    return all_sessions_activity_windows, all_sessions_new_UniqueID_windows, all_sessions_new_cell_type_id_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test correctness of data.generate_mouse_all_sessions_data() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_unqiue_neurons:  1616\n",
      "cell_type2id:  {'IN': 0, 'Pvalb': 1, 'Serpinf1': 2, 'Sncg': 3, 'Sst': 4, 'Vip': 5, 'EC': 6, 'Lamp5': 7}\n",
      "497\n",
      "104\n",
      "0 torch.Size([32, 460, 200]) torch.Size([32, 460]) torch.Size([32, 460])\n",
      "tensor([-0.0503, -0.1790,  0.1688, -0.2432, -0.2432, -0.2432, -0.2432, -0.2432,\n",
      "        -0.2432, -0.2432])\n",
      "tensor([312, 313, 314,   5, 315, 316, 317, 318, 319, 320], dtype=torch.int32)\n",
      "tensor([6, 0, 0, 7, 6, 0, 6, 6, 0, 6], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "train_dataloader, val_dataloader, num_unqiue_neurons, cell_type2id = data.generate_mouse_all_sessions_data()\n",
    "\n",
    "print('num_unqiue_neurons: ', num_unqiue_neurons)\n",
    "print('cell_type2id: ', cell_type2id)\n",
    "print(len(train_dataloader))\n",
    "print(len(val_dataloader))\n",
    "\n",
    "for idx, (batch, batch_neuron_ids, batch_cell_type_ids) in enumerate(train_dataloader):\n",
    "    batch = batch.squeeze(0)                 # remove the fake batch_size\n",
    "    batch_neuron_ids = batch_neuron_ids.squeeze(0)\n",
    "    batch_cell_type_ids = batch_cell_type_ids.squeeze(0)\n",
    "    print(idx, batch.shape, batch_neuron_ids.shape, batch_cell_type_ids.shape)\n",
    "    print(batch[0][0][:10])\n",
    "    print(batch_neuron_ids[0][:10])\n",
    "    print(batch_cell_type_ids[0][:10])\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "func2graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
